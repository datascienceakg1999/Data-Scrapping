import requests
from bs4 import BeautifulSoup
import pandas as pd


url = "https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States"


response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

table = soup.find('table', {'class': 'wikitable sortable'})


headers = [header.text.strip() for header in table.find_all('th')]


rows = table.find_all('tr')[1:]  # Skip the header row

data = []
for row in rows:
    columns = row.find_all('td')
    if len(columns) > 0:
        row_data = [col.text.strip() for col in columns]
        data.append(row_data)


df = pd.DataFrame(data, columns=headers)


csv_file_path = "us_states_and_territories.csv"
df.to_csv(csv_file_path, index=False)

print(f"Scraped data saved to {csv_file_path}")
